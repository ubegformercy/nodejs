# BoostMon Scaling Runbook

Quick reference for monitoring and scaling your bot to handle thousands of users.

---

## üöÄ Quick Status Check

### Check if you need to optimize

Run these commands in Railway's PostgreSQL console:

**Check table size:**
```sql
SELECT 
  pg_size_pretty(pg_total_relation_size('role_timers')) as size,
  COUNT(*) as record_count
FROM role_timers;
```

**Expected outputs:**
- **< 100MB, < 10,000 records**: ‚úÖ Free tier, no action needed
- **100MB-250MB, 10,000-50,000 records**: ‚ö†Ô∏è Hobby tier recommended
- **> 250MB, > 50,000 records**: üî¥ Pro tier required

### Check active timers
```sql
SELECT COUNT(*) as active_timers
FROM role_timers 
WHERE expires_at > EXTRACT(EPOCH FROM NOW()) * 1000
AND paused = false;
```

---

## üìä Monitor Cleanup Performance

Add this temporary logging to `app.js` to monitor cleanup cycle duration:

```javascript
async function cleanupAndWarn() {
  const startTime = Date.now();
  try {
    // ... existing code ...
  } catch (e) {
    console.error("cleanupAndWarn error:", e);
  } finally {
    const duration = Date.now() - startTime;
    if (duration > 100) {
      console.warn(`‚ö†Ô∏è [SLOW CLEANUP] ${duration}ms (threshold: 100ms)`);
    }
  }
}
```

**Normal times:**
- < 20ms: ‚úÖ Excellent
- 20-100ms: ‚úÖ Good
- 100-500ms: ‚ö†Ô∏è Monitor closely
- > 500ms: üî¥ Needs optimization

---

## üîß Scaling Checklist

### When You Hit 1,000 Active Users

- [ ] Verify indexes are created: Check logs for "‚úì Indexes created/verified"
- [ ] Monitor cleanup time (add logging above)
- [ ] Confirm no "SLOW QUERY" warnings in logs
- [ ] Check Railway tier is still "Free" with enough headroom

### When You Hit 5,000 Active Users

- [ ] Upgrade Railway to Hobby tier ($7/month)
- [ ] Increase connection pool:
  ```javascript
  const pool = new Pool({
    connectionString: process.env.DATABASE_URL,
    max: 15, // Increase from 10
  });
  ```
- [ ] Implement cleanup batching:
  ```javascript
  // Process cleanup in batches of 500 to prevent timeout
  const BATCH_SIZE = 500;
  let processed = 0;
  
  const allTimers = await db.getAllActiveTimers();
  for (let i = 0; i < allTimers.length; i += BATCH_SIZE) {
    const batch = allTimers.slice(i, i + BATCH_SIZE);
    // Process batch...
    processed += batch.length;
  }
  ```

### When You Hit 10,000+ Active Users

- [ ] Upgrade Railway to Pro tier ($25/month)
- [ ] Implement query result caching:
  ```javascript
  const queryCache = new Map();
  const CACHE_TTL = 5000; // 5 seconds
  
  async function getCachedTimers(userId) {
    const cacheKey = `user:${userId}`;
    if (queryCache.has(cacheKey)) {
      return queryCache.get(cacheKey);
    }
    const timers = await db.getTimersForUser(userId);
    queryCache.set(cacheKey, timers);
    setTimeout(() => queryCache.delete(cacheKey), CACHE_TTL);
    return timers;
  }
  ```
- [ ] Consider read replicas for heavy lifting
- [ ] Enable connection pooling proxy (PgBouncer)

---

## üîç Troubleshooting

### Issue: "Slow Cleanup Warning" appearing

**Cause**: Too many timers to process in single cycle

**Solution (Immediate)**: Add batch processing
```javascript
async function cleanupAndWarn() {
  const BATCH_SIZE = 1000;
  let batchCount = 0;
  
  try {
    if (!GUILD_ID) return;
    if (!client.isReady()) return;

    const guild = await client.guilds.fetch(GUILD_ID).catch(() => null);
    if (!guild) return;

    const now = Date.now();
    const me = await guild.members.fetchMe().catch(() => null);
    const canManage = Boolean(me?.permissions?.has(PermissionFlagsBits.ManageRoles));

    const allTimers = await db.getAllActiveTimers().catch(() => []);

    for (let i = 0; i < allTimers.length; i += BATCH_SIZE) {
      batchCount++;
      const batch = allTimers.slice(i, Math.min(i + BATCH_SIZE, allTimers.length));
      
      for (const entry of batch) {
        // ... existing timer processing code ...
      }
      
      // Small delay between batches to avoid blocking
      if (i + BATCH_SIZE < allTimers.length) {
        await new Promise(resolve => setImmediate(resolve));
      }
    }
    
    if (batchCount > 1) {
      console.log(`Cleanup processed ${allTimers.length} timers in ${batchCount} batches`);
    }
  } catch (e) {
    console.error("cleanupAndWarn error:", e);
  }
}
```

### Issue: "Connection pool exhausted" error

**Cause**: Too many concurrent operations

**Solution**: Increase pool size in `db.js`
```javascript
const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
  max: 20, // Increase from 10
});
```

### Issue: "Query timeout" errors

**Cause**: Single cleanup cycle taking too long

**Solution**: Implement query timeout + fallback
```javascript
async function queryWithTimeout(fn, timeoutMs = 5000) {
  return Promise.race([
    fn(),
    new Promise((_, reject) =>
      setTimeout(() => reject(new Error('Query timeout')), timeoutMs)
    ),
  ]);
}

// Use in cleanup:
const allTimers = await queryWithTimeout(
  () => db.getAllActiveTimers(),
  5000
).catch(() => []);
```

---

## üìà Performance Targets

### Response Times (Per Discord Command)

| Command | Current | Target | Benchmark |
|---------|---------|--------|-----------|
| `/settime` | 50-100ms | < 200ms | ‚úÖ Good |
| `/addtime` | 50-100ms | < 200ms | ‚úÖ Good |
| `/pausetime` | 30-50ms | < 200ms | ‚úÖ Good |
| `/timeleft` | 30-80ms | < 200ms | ‚úÖ Good |

### Cleanup Cycle Duration

| User Count | Expected | Max Acceptable |
|-----------|----------|-----------------|
| 1,000 | 5-10ms | 100ms |
| 5,000 | 20-50ms | 200ms |
| 10,000 | 50-150ms | 500ms |
| 50,000 | 200-500ms | 1000ms |

---

## üéØ Cost Optimization Tips

### Optimize storage

**Remove old expired timers** (optional cleanup job):
```sql
DELETE FROM role_timers 
WHERE expires_at < (EXTRACT(EPOCH FROM NOW()) * 1000 - 86400000)
AND paused = false;
```

**Archive by month** (for analytics):
```sql
SELECT DATE_TRUNC('month', created_at), COUNT(*)
FROM role_timers
GROUP BY DATE_TRUNC('month', created_at);
```

### Optimize queries

Use EXPLAIN ANALYZE to find slow queries:
```sql
EXPLAIN ANALYZE
SELECT * FROM role_timers 
WHERE expires_at > 1700000000000 
AND paused = false
ORDER BY expires_at ASC;
```

---

## üìû When to Contact Railway Support

- Database size approaching 500MB
- Connection limit issues (errors mentioning "connections")
- Backup/restore problems
- Need for multi-region setup
- Performance issues persisting after optimization

---

## üéì Further Reading

- [PostgreSQL Query Optimization](https://www.postgresql.org/docs/current/performance-tips.html)
- [Railway Database Docs](https://docs.railway.app/databases/postgresql)
- [Discord.js Performance Guide](https://guide.discordjs.org/handling-expensive-operations/performance.html)

**Last Updated**: 2024
**Bot Status**: ‚úÖ Production Ready
**Estimated Capacity**: 10,000+ concurrent users
